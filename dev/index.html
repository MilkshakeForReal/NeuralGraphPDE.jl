<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · NeuralGraphPDE.jl</title><script data-outdated-warner src="assets/warner.js"></script><link rel="canonical" href="https://MilkshakeForReal.github.io/NeuralGraphPDE.jl/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.044/juliamono.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>NeuralGraphPDE.jl</a></span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li><a class="tocitem" href="#Features"><span>Features</span></a></li><li><a class="tocitem" href="#Implementing-custom-layers"><span>Implementing custom layers</span></a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="tutorials/graph_node/">Neural Graph Ordinary Differential Equations</a></li></ul></li><li><span class="tocitem">API Reference</span><ul><li><a class="tocitem" href="api/layers/">Layers</a></li><li><a class="tocitem" href="api/utilities/">Utilities</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/MilkshakeForReal/NeuralGraphPDE.jl/blob/main/docs/src/index.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="NeuralGraphPDE"><a class="docs-heading-anchor" href="#NeuralGraphPDE">NeuralGraphPDE</a><a id="NeuralGraphPDE-1"></a><a class="docs-heading-anchor-permalink" href="#NeuralGraphPDE" title="Permalink"></a></h1><p>Documentation for <a href="https://github.com/MilkshakeForReal/NeuralGraphPDE.jl">NeuralGraphPDE</a>.</p><h2 id="Features"><a class="docs-heading-anchor" href="#Features">Features</a><a id="Features-1"></a><a class="docs-heading-anchor-permalink" href="#Features" title="Permalink"></a></h2><ul><li>Layers and graphs are coupled and decoupled at the same time: You can bind a graph to a layer at initialization, but the graph is stored in <code>st</code>, not in the layer. They are decoupled in the sense that you can easily update or change the graph by changing <code>st</code>:</li></ul><pre><code class="language-julia hljs">using NeuralGraphPDE, GraphNeuralNetworks, Random, Lux
g = rand_graph(5, 4, bidirected = false)
x = randn(3, g.num_nodes)

# create layer
l = ExplicitGCNConv(3 =&gt; 5, initialgraph = g)

# setup layer
rng = Random.default_rng()
Random.seed!(rng, 0)

ps, st = Lux.setup(rng, l)

# forward pass
y, st = l(x, ps, st)    # you don&#39;t need to feed a graph explicitly

#change the graph
new_g = rand_graph(5, 7, bidirected = false)
st = updategraph(st, new_g)

y, st = l(x, ps, st)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">([0.03958144261952111 -0.026616179780779865 … 0.06522956651356943 -0.3501238372392267; 1.272802901565284 0.561095148812716 … 0.5162923283344266 -0.4015674997254187; … ; 1.784922314502185 0.7792083490785124 … 0.9584281102919623 -1.163458413032222; 0.5082830047778734 0.20053457892527776 … 0.42718721171710433 -0.8077703940996641], (graph = GNNGraph(5, 7),))</code></pre><ul><li>You can omit the key argument <code>initalgraph</code> at initialization, and then call <code>updategraph</code> on <code>st</code>:</li></ul><pre><code class="language-julia hljs">g = rand_graph(5, 4, bidirected = false)
x = randn(3, g.num_nodes)

model = Chain(ExplicitGCNConv(3 =&gt; 5),
              ExplicitGCNConv(5 =&gt; 3))  # you don&#39;t need to use `g` for initalization
# setup layer
rng = Random.default_rng()
Random.seed!(rng, 0)

ps, st = Lux.setup(rng, model) # st.graph is empty
st = updategraph(st, g) # put the graph in there

# forward pass
y, st = model(x, ps, st)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">([2.939920033436491 0.35247752411446814 … 3.241867946080837 1.335401456740158; 2.8078203639650563 0.48827873036105707 … 3.101073168902136 1.3465387355873; 0.5139659340971715 0.48065867152233877 … 0.45804316894182473 0.1642207211927714], (layer_1 = (graph = GNNGraph(5, 4),), layer_2 = (graph = GNNGraph(5, 4),)))</code></pre><ul><li><p>An unified interface for graph level tasks. As pointed out <a href="https://discourse.julialang.org/t/using-a-variable-graph-structure-with-neuralode-and-gcnconv/78881">here</a>, GNNs are difficult to work well with other neural networks when the input graph is changing. This will not be an issue here. You have an unified interface <code>y, st = model(x, ps, st)</code>. In <code>GraphNeuralNetwork.jl</code>, you can use <code>Chain(GNNChain(...), Dense(...))</code> for graph levels tasks but you will not be able to feed a graph to <code>Chain(Dense(...), GNNChain(...))</code>.</p></li><li><p>Having node embeddings and other nontrainable features such as spaital coordinates? Thanks to <a href="http://lux.csail.mit.edu/dev/manual/migrate_from_flux/#implementing-custom-layers">Lux</a>, trainable parameters and nonntrainable parameters are seperately stored in <code>x</code> and <code>st</code>. We will not have to unpack and merge them over and over again.</p></li></ul><h2 id="Implementing-custom-layers"><a class="docs-heading-anchor" href="#Implementing-custom-layers">Implementing custom layers</a><a id="Implementing-custom-layers-1"></a><a class="docs-heading-anchor-permalink" href="#Implementing-custom-layers" title="Permalink"></a></h2><p><code>NeuralGraphPDE</code> basically share the same interface with <code>Lux.jl</code>. You may want to take a look at its <a href="http://lux.csail.mit.edu/dev/manual/migrate_from_flux/#implementing-custom-layers">doc</a> first. Based on that, <code>NeuralGraphPDE</code> provides two abstract types, <code>AbstractGNNLayer</code> and <code>AbstractGNNContainerLayer</code>, they are subtypes of <code>AbstractExplicitLayer</code> and <code>AbstractExplicitContainerLayer</code>, respectively. You should subtype your custom layers to them.</p><h3 id="AbstractGNNLayer"><a class="docs-heading-anchor" href="#AbstractGNNLayer">AbstractGNNLayer</a><a id="AbstractGNNLayer-1"></a><a class="docs-heading-anchor-permalink" href="#AbstractGNNLayer" title="Permalink"></a></h3><p>You can define a custom layer with the following steps:</p><p>Step 1. Define your type of the layer and add <code>initialgraph</code> as a field.</p><pre><code class="nohighlight hljs">struct MyGNNLayer{F} &lt;: AbstractGNNLayer
    initialgraph::F
    ...
end</code></pre><p>Step 2. Define <code>initialparameters</code> as in <code>Lux</code>. The default <code>initialstates</code> returns <code>(graph = GNNGraph(...))</code>, so this is optional. If you want to put more things in <code>st</code> then you need to overload <code>initialstates</code> as well.</p><pre><code class="language-julia hljs">function initialstates(rng::AbstractRNG, l::AbstractGNNLayer)
    (graph = l.initialgraph(), otherstates)
end</code></pre><p>In this case, it is recommended to also overload <code>statelength</code>, it should be like</p><pre><code class="language-julia hljs">statelength(l::AbstractGNNLayer) = 1 + length(otherstates) # 1 for the graph</code></pre><p>Step 3. Define the constructor(s) that has the keyword argument <code>initialgraph=initialgraph</code>.</p><pre><code class="nohighlight hljs">function MyGNNLayer(...; initialgraph=initialgraph)
  initalgraph = wrapgraph(initialgraph) # always wrap initialgraph so the input can be a graph or a function
  MyGNNLayer{typeof(initialgraph), ...}(initialgraph,...)
end</code></pre><p>Step 4. Define the forward pass. Keep in mind that the graph is stored in <code>st</code>. It is recommended to store nontrainable node features in the graph.</p><pre><code class="nohighlight hljs">function (l::MyGNNLayer)(x,ps,st)
    g = st.graph
    s = g.ndata # nontrainable node features, if there is any
    function message(xi, xj, e)
        ...
        return m
    end
    xs = merge(x, s) # assuming x is a named tuple
    return propagte(message, g, l.aggr, xi = xs, xj = xs), st
end</code></pre><h3 id="AbstractExplicitContainerLayer"><a class="docs-heading-anchor" href="#AbstractExplicitContainerLayer">AbstractExplicitContainerLayer</a><a id="AbstractExplicitContainerLayer-1"></a><a class="docs-heading-anchor-permalink" href="#AbstractExplicitContainerLayer" title="Permalink"></a></h3><p>You should only subtype your layer to <code>AbstractExplicitContainerLayer</code> then</p><ol><li>you need to write a custom message function, and</li><li>the layer contains other layers.</li></ol><p>For the most part it will look identical to defining <code>AbstractGNNLayer</code>. You just need to treat the message function more carefully.</p><pre><code class="nohighlight hljs">function message(xi, xj, e)
        ...
        m, st.nn = nn(..., st.nn)
        st = merge(st, (nn = st_nn,))
        return m
end</code></pre><p>Note that if you have only one neural layer insider a <code>AbstractExplicitContainerLayer</code>, then the parameters will be reduced but not the states.</p><pre><code class="language-julia hljs">julia&gt; l = ExplicitEdgeConv(nn, initialgraph = g)


julia&gt; rng = Random.default_rng()


julia&gt; ps, st = Lux.setup(rng, l)


julia&gt; ps
(weight = Float32[0.22180015 -0.09448394 … -0.41880473 -0.49083555; -0.23709725 0.05150031 … 0.48641983 0.14893274; … ; 0.42824164 0.5589718 … -0.5763395 0.18395355; 0.25994122 0.22801241 … 0.59201854 0.3832495], bias = Float32[0.0; 0.0; … ; 0.0; 0.0;;])

julia&gt; st
(ϕ = NamedTuple(), graph = GNNGraph(3, 4))</code></pre></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="tutorials/graph_node/">Neural Graph Ordinary Differential Equations »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.19 on <span class="colophon-date" title="Saturday 25 June 2022 06:13">Saturday 25 June 2022</span>. Using Julia version 1.7.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
